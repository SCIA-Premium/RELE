{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction à l'apprentissage par renforcement\n",
    "# TP 1 - les manchots multi-bras\n",
    "\n",
    "Etudiant·e : AJOUTER VOTRE NOM ICI\n",
    "\n",
    "1/4 de la note finale est liée à la mise en forme : \n",
    "\n",
    "* pensez à nettoyer les outputs inutiles (installation, messages de débuggage, ...)\n",
    "* soignez vos figures : les axes sont-ils faciles à comprendre ? L'échelle est adaptée ? \n",
    "* commentez vos résultats : vous attendiez-vous à les avoir ? Est-ce étonnant ? Faites le lien avec la théorie.\n",
    "\n",
    "Ce TP reprend l'exemple d'un médecin et de ses vaccins. Vous allez comparer plusieurs stratégies et trouver celle optimale.\n",
    "Un TP se fait en groupe de 2 à 4. Aucun groupe de plus de 4 personnes. \n",
    "\n",
    "Vous allez rendre le TP dans une archive ZIP. L'archive ZIP contient ce notebook au format `ipynb`, mais aussi exporté en PDF & HTML. \n",
    "L'archive ZIP doit aussi contenir un fichier txt appelé `groupe.txt` sous le format:\n",
    "\n",
    "```\n",
    "Nom1, Prenom1, Email1, NumEtudiant1\n",
    "Nom2, Prenom2, Email2, NumEtudiant2\n",
    "Nom3, Prenom3, Email3, NumEtudiant3\n",
    "Nom4, Prenom4, Email4, NumEtudiant4\n",
    "```\n",
    "\n",
    "Un script vient extraire vos réponses : ne changez pas l'ordre des cellules et soyez sûrs que les graphes sont bien présents dans la version notebook soumise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install matplotlib tqdm numpy ipympl opencv-python\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "!jupyter labextension install jupyter-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "\n",
    "import typing as t\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "K = 5 # num arms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Présentation du problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArmBernoulli:\n",
    "    def __init__(self, p: float, random_state: t.Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Vaccine treatment following a Bernoulli law (mean is p and variance is p(1-p)\n",
    "        Args:\n",
    "             p (float): mean parameter\n",
    "             random_state (int): seed to make experiments reproducible\n",
    "             \n",
    "        >>> arm = ArmBernoulli(0.5, 0)\n",
    "        >>> arm.sample(5)\n",
    "        tensor([ True, False,  True,  True,  True])\n",
    "        \"\"\"\n",
    "        if random_state is not None:\n",
    "            torch.random.manual_seed(random_state)\n",
    "        self.immunity_rate = p\n",
    "\n",
    "    def sample(self, n: int = 1):\n",
    "        return torch.rand(n) < self.immunity_rate\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'<ArmBernoulli p={self.immunity_rate}' \n",
    "\n",
    "def generate_arms(num_arms: int):\n",
    "    means = torch.rand(K)\n",
    "    MAB = [ArmBernoulli(m) for m in means]\n",
    "    assert MAB[0].immunity_rate == means[0]\n",
    "    assert (MAB[0].sample(10) <= 1).all() and (MAB[0].sample(10) >= 0).all() \n",
    "    return MAB\n",
    "\n",
    "MAB = generate_arms(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note importante :** pour la suite, les tests seront faits avec 10 MAB différents ou plus pour réduire le bruit de simulation. \n",
    "\n",
    "Ce TP reprend l'exemple du médecin présenté en cours.\n",
    "\n",
    "\n",
    "**Q1. Que vaut $\\mu^*$ avec `random_state = 0`? Comment est définie la récompense $R_k$ ? Que représente concrètement le regret dans cet exemple ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Cas classique des bandits manchots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## I.a. Solution Gloutonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le médecin fonctionne sur deux phases :\n",
    "\n",
    "1. **Exploration :** N patients reçoivent une dose d'un vaccin choisi aléatoirement. Le médecin calcule le taux d'immunisation empirique :\n",
    "\n",
    "$$\\bar{R_i} = \\frac{1}{T_i} \\sum_{k=0}^{N-1} \\chi_{v_k,i}R_k,$$\n",
    "\n",
    "avec $T_i = \\sum_{k=0}^{N-1} \\chi_{v_k,i}$.\n",
    "\n",
    "\n",
    "2. **Exploitation :** Le vaccin $v_i = \\arg\\max_j \\bar{R_j}$ est utilisé pour les M patients suivants. C'est la phase de test.\n",
    "\n",
    "**Q2. Implémentez la solution gloutonne avec N = 50 et M = 500 et testez la avec 100 MAB différents (tous ont 5 vaccins). On s'intéresse à la variable aléatoire \"la phase d'exploration a trouvé le bon vaccin\". Quelle est l'espérance empirique de cette variable ? Et son écart-type ? Calculez de même l'espérance et l'écart-type du regret sur vos 100 simulations.**\n",
    "\n",
    "Pour rappel, le regret est défini par :\n",
    "\n",
    "$$r_n = n\\mu^* - \\sum_{k=0}^{n-1} R_k$$\n",
    "\n",
    "**Attention :** $n$ est le nombre total de patients, donc ici $N + M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "M = 500\n",
    "\n",
    "# We create a list with all the  results for N patients\n",
    "vaccines = []\n",
    "for _ in range(N):\n",
    "    random_vac = random.randint(0, K - 1)\n",
    "    vaccines.append(MAB[random_vac])\n",
    "\n",
    "def get_vaccines_efficency(vaccines, N):\n",
    "    r_k = [vaccine.sample() for vaccine in vaccines]\n",
    "    T_i = {vaccines[i] : vaccines.count(vaccines[i]) for i in range(N - 1)}\n",
    "    result = {}\n",
    "    for vaccine_i in vaccines:\n",
    "        sum_x_rk = 0\n",
    "        k = 0\n",
    "        for vaccine_k in vaccines:\n",
    "            X = int(vaccine_i == vaccine_k)\n",
    "            sum_x_rk += X * r_k[k]\n",
    "            k += 1\n",
    "        result[vaccine_i] = (1/T_i[vaccine_i]) * sum_x_rk\n",
    "    return result\n",
    "\n",
    "R_i = get_vaccines_efficency(vaccines, N)\n",
    "\n",
    "# We get the best vaccine based on the injection of the N patients\n",
    "best_vaccine_N = R_i[0]\n",
    "for v in vaccines:\n",
    "    if v.mean > best_vaccine_N.mean:\n",
    "        best_vaccine_N = v\n",
    "print(\"Best vaccine for N: \", best_vaccine_N)\n",
    "\n",
    "    \n",
    "# Regret\n",
    "def get_regret(vaccines, N, nu_star):\n",
    "    r_ks = sum([int(vaccine.sample()) for vaccine in vaccines])\n",
    "    return N * nu_star - r_ks\n",
    "\n",
    "print(get_regret(vaccines + vaccines_M, N + M, # FIXME))\n",
    "\n",
    "#### FIX EVERYTHING BECAUSE NOT GOOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3. On propose d'améliorer l'algorithme précédant en mettant à jour les taux d'immunisation empiriques $\\bar{R}_i$ pendant la d'exploration. Notez vous une amélioration du regret ? Proposez un exemple dans lequel cette mise à jour ne changera rien.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4. Créez une figure contenant deux sous-figures : à gauche, le taux d'immunisation empirique $\\bar{R}_i$ pour les 5 vaccins ; à droite, le regret $r_n$. La figure sera animée avec les patients : chaque frame $k$ de l'animation représente le vaccin que l'on donne au $k$-ième patient.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5. On étudie maintenant l'influence de la taille du training set $N$. On considère que N+M est une constante, puis on fait varier N entre K et M. Calculez le regret pour ces différentes tailles du training set  différents MAB et representez le regret moyen, le regret min et max (vous devriez trouver une courbe en U ou en V pour le regret moyen). Quelle est la taille optimale du training set ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## I.b. Borne inférieure de Lai & Robbins [Lai et Robbins, 1985]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un modèle de manchot de Bernoulli (équivalent au problème étudié), la borne inférieure de Lai et Robbins [Lai et Robbins, 1985] stipule que :\n",
    "\n",
    "$$\\lim \\inf_{n\\rightarrow \\infty} \\frac{\\sum_{k=0}^{n-1} R_k}{\\log n} \\geq \\sum_{i~\\text{tel que}~\\mu_i \\lt \\mu^*} \\frac{\\mu^∗−\\mu_i}{\\text{KL}(\\mu_i, \\mu^*)}  :=C(\\mu)$$\n",
    " \n",
    " avec $\\text{KL}(x, y) = x \\log(x/y) + (1 − x) \\log((1 − x)/(1 − y))$ (distance de Kullback-Leibler) et  $\\sum_{k=0}^{n-1} R_k$ la récompense obtenue sur $n$ patients (avec un algorithme optimal). \n",
    " \n",
    " \n",
    "**Q6. Justifiez pourquoi cette borne signifie que la machine optimale est jouée exponentiellement plus souvent que les autres machines.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7. Tracez le regret issu de la borne de Lai & Robbins et comparez le au regret obtenu avec l'algorithme glouton.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.c. Upper Confidence Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet algorithme améliore la version précédente en ajoutant un biais lié à la fréquentation de chaque vaccin :\n",
    "\n",
    "$$\\hat{R}_i = \\bar{R}_i + \\sqrt{\\frac{C\\log{n}}{T_i}}$$,\n",
    "\n",
    "avec $C=2$.\n",
    "\n",
    "**Q8. Implémentez la modification de cette algorithme. Conservez les deux phases exploration/exploitation décrites ci-dessus. En prenant les valeurs de $N$ et $M$ trouvées à la question Q5, quel regret obtenez-vous ? Faites l'expérience avec au moins 10 MAB différents (tous ayant 5 vaccins) afin de calculer la moyenne et l'écart-type du regret.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9. Reprenez la questions Q4 avec cette algorithme. Dans la figure de gauche, vous representerez $\\bar{R}_i$ et $\\hat{R}_i$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10. Reprenez la question Q5 avec cette algorithme. Concluez sur l'utilité (ou l'inutilité) de la phase d'exploration. Comparez les performances d'UCB avec celles de l'algorithme glouton.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11. Testez différentes valeurs pour $C$ et trouvez sa valeur optimale expérimentalement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echantillonnage de Thomson\n",
    "\n",
    "Cet algorithme propose de modéliser la variable aléatoire de chaque vaccin avec une loi $\\beta$ dont les paramètres $a$ et $b$ correspondent au nombre de patients que le vaccin a immunisés (resp. non immunisés).\n",
    "\n",
    "Pour chaque patient, on tire un valeur aléatoire pour la loi $\\beta$ décrivant chaque vaccin, puis on choisit le vaccin avec la plus grande valeur tirée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12. Implémentez cet algorithme. Conservez les deux phases exploration/exploitation décrites ci-dessus. En prenant les valeurs de $N$ et $M$ trouvées à la question Q5, quel regret obtenez-vous ? Faites l'expérience avec au moins 10 MAB différents (tous ayant 5 vaccins) afin de calculer la moyenne et l'écart-type du regret.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13. Reprenez la question Q4, mais cette fois-ci, vous representerez le taux d'immunisation empirique avec un [graphique en violon](https://en.wikipedia.org/wiki/Violin_plot) qui représente la loi beta associée à chaque vaccin.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14. Représentez son regret pour différentes tailles du training set (comme dans la Q5). Comparez le regret avec les autres algorithmes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "**Q15. Calculez le regret des algorithmes glouton, UCB & Thomson lorsqu'il y a un grand nombre de vaccins disponibles (K=100) (on prendra N=100). Faites le lien avec la [malédiction de la dimension](https://fr.wikipedia.org/wiki/Fl%C3%A9au_de_la_dimension).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Ajoutez votre commentaire ici]*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
